# -*- coding: utf-8 -*-
"""speech_to_image.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mOWEgVUSCI9kuxrNXvRR8Z2owR9uZ3IJ
""


import streamlit as st
from whisper_model import transcribe_audio
from stable_diffusion import generate_image
from sentiment_analysis import analyze_sentiment
from pydub import AudioSegment
import tempfile

st.title("Speech-to-Image Live Conversion")
st.write("Upload an audio file (MP3 or WAV) to transcribe, analyze, and generate an image!")

# Function to convert MP3 to WAV
def convert_to_wav(audio_file):
    audio = AudioSegment.from_file(audio_file, format="mp3")
    temp_wav_path = tempfile.NamedTemporaryFile(delete=False, suffix=".wav").name
    audio.export(temp_wav_path, format="wav")
    return temp_wav_path

# File uploader
audio_file = st.file_uploader("Upload your audio file", type=["mp3", "wav"])
if audio_file:
    # Convert MP3 to WAV if needed
    if audio_file.name.endswith(".mp3"):
        st.write("Converting MP3 to WAV...")
        audio_path = convert_to_wav(audio_file)
    else:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_file.write(audio_file.read())
            audio_path = tmp_file.name

    st.success("Audio file ready for processing!")

    # Transcription
    st.write("Transcribing audio...")
    transcription = transcribe_audio(audio_path)
    st.success(f"Transcription: {transcription}")

    # Sentiment Analysis
    st.write("Analyzing sentiment...")
    sentiment = analyze_sentiment(transcription)
    st.success(f"Sentiment: {sentiment['label']} (Confidence: {sentiment['score']:.2f})")

    # Image Generation
    st.write("Generating image...")
    image = generate_image(transcription)
    st.image(image, caption="Generated Image", use_column_width=True)
